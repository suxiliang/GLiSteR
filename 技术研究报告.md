# 技术研究报告

文档修订历史

|序号|修订原因|版本号|作者|修订日期|备注|
|:---:|:---:|:---:|:---:|:---:|:---:|
|1|添加内容|1.0.0|丁|2023/1/xx|22|

## 问题聚焦

> 初赛阶段完成

### 问题描述

随着生活水平的提高和生活方式的变迁，音乐已经成为许多人生活中重要的一部分。随着互联网与电子设备的发展，人们听音乐的方式由留声机、磁带机到MP3，最终形成现在以智能手机为主的阶段。音乐作为一种雅俗共赏的艺术形式，已经深刻融入人们生活的点滴中，见证听众一天天一年年的生活，成为一段段过往记忆、生活日常的容器，承载用户一条条生活片断中的心情。

> 完犊子不会写了，先暂停这部分。

但是，多数听歌应用仍按照互联网时代前的方式以提供音乐播放能力作为核心功能，围绕音乐播放拓展社交等功能，这其实忽视了音乐在移动互联网时代与个人生活强烈的参与程度。事实上，由于我们可以随时随地戴上耳机，掏出手机开始欣赏音乐，音乐十分深入的参与到我们的生活中，以至于用户欣赏的歌曲、歌单与用户自己此时此刻的心情、情绪有了难舍难分的联系。

一方面，音乐软件的推荐机制普遍根据风格——歌手——流派——听歌次数进行用户模型的建立。然而，用户每天打开听歌应用时的心情是多样的，对一首歌曲的体验是多样的；大量用户在听歌时积累了大量心情和体验，使得一首歌曲一定程度上成为用户共同记忆的载体，使得音乐有了在流派、歌手以外的一种特征。对于用户自身来讲，拥有情绪特点的歌曲以及自身此刻情绪的结合，可以获得更贴心、更懂自己的听歌体验，而且有些时候用户并不知道自己想听什么，但是知道自己此刻的心情，这时候用户希望能够有一个能够根据用户的心情推荐歌曲的应用。又或者，当用户想要感受图书馆内、候车厅内的氛围时，甚至只是擦肩而过的人，他们都会有一种共同的心情，这时候用户希望能够有一个能够根据用户的心情推荐歌曲的应用。

另一方面，用户对歌曲的欣赏和体验在当下往往是一种单纯的输入过程，事实上，用户需要一些渠道输出自己的想法。主流应用采取的大多是社区设计，但是社区设计的核心是社交，而用户的想法往往是单纯的，用户希望能够有一个能够捕获用户的心情的应用，而不是一个社交平台。

从上述两个方面来看，我们需要做的改进对设备有一定依赖，一些功能需要穿戴设备提供信息，另一些可能需要PC来提供计算能力。因此，我们需要应用具有跨平台的能力，并且能够自适应的实现信息获取，以及动态的计算方式，从而实现用户的无感体验。

### 问题抽象

> 将项目要解决的具体问题抽象转化为技术问题

解决上述问题的关键在于解决：一是要通过一定的技术手段，将用户的心情和歌曲的情绪特点进行提取分析并结合起来，从而实现用户心情与歌曲情绪特点的匹配；二是要在用户有意愿的情况下，通过更加隐私、无缝的方式实现一定范围内的用户心情和歌曲情绪特点的共享；三是要让用户能够记录自己的心情特征，并通过一定的方式输出自己的想法；四是将信息提取、推荐和创作的功能与设备深入结合，根据场景智能选择计算方式，从而得到体验更流畅的音乐体验。

- 用户与歌曲情绪特点的提取和识别。
- 基于情绪特征、具有场景交互交互能力的歌曲推荐。
- 以用户和歌曲情绪特点为基础的创作系统。
- 智能无感的跨平台信息共享和计算能力。

### 问题定位

> 指出该问题所属的业务领域与技术领域

该问题是一个跨模态特征提取、推荐系统、智能创作和分布式计算相关的综合问题，属于对音乐的情感分析、推荐和创作的一种深入挖掘。本项目旨在挖掘用户与歌曲的情感特征，围绕这一宗旨实现对用户情绪特征的采集、管理统计，歌曲情绪特征的分析、提取，用户与歌曲情绪特征的匹配，以及基于情绪特征的推荐、创作等功能。

从技术上来讲，本项目涉及到的技术领域有：音乐情感分析、文本情感分析、跨模态特征融合、对话任务、推荐系统、智能创作、分布式计算、跨平台信息共享等。

### 问题评估

> 分析问题本身的技术性、普适性、热度等特点。

#### 技术性

本项目的核心需求要做到从文本、音乐等不同模态中提取情绪特征，将多模态下的特征进行特征空间对齐和融合，最终借助智能算法实现情绪特征的生成，并能够在不同场景下动态调整；其次，本项目要实现具有场景感知、环境感知、情绪感知能力的音乐互动，还要求应用具有一定近场通信和交互能力的能力；要实现分层次、具有多种情景下的工作能力的智能推荐，需要设计一个比较灵活强大的推荐系统；要实现智能创作，需要设计一个能够根据用户的情绪特征和歌曲的情绪特征进行创作的系统，并且支持以插件的形式拓展下游任务；要实现智能无感的跨平台信息共享和计算能力，需要提供用户不同设备和云端之间的智能算力调度和信息共享机制，并且在不同平台上提供不同压缩程度的模型部署。

上述过程对应用的开发提出了许多要求，例如客户端在不同平台上的兼容适配、相互调用，以及对不同平台的算力调度和信息共享；服务端的架构配置、功能实现以及对模型的压缩和部署，计算资源的调度管理；客户端的热更新能力，服务端的横向扩展能力、抗压能力等。

本项目在人工智能的应用上，涉及到了多个领域的技术，包括音乐情感分析、文本情感分析、跨模态特征融合、对话任务、推荐系统、智能创作等领域；开发技术上涉及到了多个平台的兼容适配、算力调度和信息共享、模型压缩和部署等技术。这些技术都是比较新的技术，需要对这些技术进行深入的研究和探索，因此本项目具有很强的技术性和挑战性，包含对现有技术的深入研究和对新技术的探索。

#### 普适性

本项目的应用场景是在不同的场景下，根据用户的情绪特征和歌曲的情绪特征进行匹配，从而实现歌曲推荐、智能创作等功能。这些功能都是普适的，不仅可以应用于音乐领域，还可以应用于其他领域，例如电影、电视剧、小说等领域。

本项目涉及的技术也是普适的，能够为多模态特征下的情感分析、跨模态特征融合、推荐系统、智能创作等领域提供技术参考，同时涉及到非标准化信息的保存和处理，不同设备之间的信息共享、算力调度和身份识别等技术，以及服务端的架构配置、功能实现以及对模型的压缩和部署，计算资源的调度管理等，都是许多领域将AI投入生产时需要解决的问题。

因此，本项目的技术方案具有很强的普适性，能够同时为人工智能研究领域和软件开发提供参考。

#### 热度

音乐相关的应用在市场中始终占据着极其重要的地位，从艺术的角度来看，音乐具有十分丰富的信息和强大的扩散、传播能力；近年来伴随人工智能领域的飞速发展，多媒体、多模态等细分领域涌现许多突破性的成果，借助AI技术使得落地一种更”懂“用户的产品具有了可能性；与此同时，在万物互联的大背景下，智能设备之间的交互、信息共享成为新的热点，探索如何利于不同设备的特性构建无感知、高性能、高可用的服务体系同样是我们的目标之一。

### 问题分解

> 根据问题的规模进行分解，将问题分解为若干个子问题，并给出子问题的难度及子问题之间的依赖关系。

#### 用户情绪特征提取

本项目的主要数据支撑就是基于用户的“情绪信息”，其来源非常丰富，包括但不限于：

- 智能穿戴设备检测身体指标
- 智能设备使用情况
- 用户听歌风格、偏好
- 用户与应用的交互

从技术上，需要做到充分利用各种方式采集的数据绘制合适的用户画像，并与音乐的特征空间做好匹配。

#### 多层次、可变且可感知环境的推荐系统

本项目根据使用场景的规模，需要具有以下能力：

- 极近距离下的应用通信和数据分享
- 相同空间内的信息融合和推荐

#### 多设备的信息共享、算力调度

为了实现高校的端云结合与设备互联，充分发挥不同设备的特性，本项目需要实现：

- 复杂计算任务向PC调度
- 不同设备下的模型压缩和部署
- 本地运算和云端服务的协同

#### 优雅的人工智能创作

#### 用户状态感知和引导

需要对检测到用户的心情特征进行相应的反馈。

## 相关工作

> 初赛阶段完成
>
> 罗列至少三项与之相关的已有技术方案，尽可能是近三年内的技术方案。

### 多模态情绪识别

借助多模态特征进行情绪识别是人工智能技术的重要研究方向之一，涉及多模态特征融合、情绪识别等子问题，有非常大的研究潜力，并且具有很高的落地价值。本项目中任务的目标是借助多模态的信息判断用户的情绪。

情感是大脑的高级活动，它是一种复杂的心理和生理状态，高级活动包括记忆、学习、决策和情绪等。情绪是情感的一个外部表现，是我们对事件内在或外在的反应。一个成功的人通常要同时具备高智商和高情商。情商反映一个人控制调节自己情感的能力，以及处理自己与他人之间情感关系的能力。情感很重要，它会影响我们做决策。情感计算要赋予计算机像人一样的观察理解和生成情感特征的能力，最终使得计算机像人一样进行自然亲近和生动的交互。情感计算中基本问题包括情绪识别。

情绪至今没有明确的定义，但是可以简单的理解成“brief brain and body episode that facilitates a response to a significant event”。在计算机领域，要特别注意sentiment analysis（情感分析）的区别，只有当情感的持有者面对一个实体或物体被卷入或唤起的情况时，情感才会表现出来。简单来说就是sentiment必须要有一个客体，而emotion更多的是主观的感受。同时sentiment是一个比较持续的过程，而emotion就更考虑变化。事实上，在面部表情识别中，就有论文利用光流信息提升识别的准确率。

![emotion和feeling](https://img-blog.csdnimg.cn/20210201135908412.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5MzM3MzMy,size_16,color_FFFFFF,t_70)

模态（Modal）是指人接受信息的特定方式，多模态（Multi-Modal）就是不同的信息模态例如语音（包括语义和非语义信息等）、视频（包括RGB信息、深度信息、光流信息等）、文本信息进行自动化系统的学习。与多模态学习联系紧密的跨模态（cross-modal）学习是利用其他模态的信息增强某一个模态信息的学习效果，比如利用视频信息增强对音频数据的训练效果，但是测试时只利用音频数据测试。

在情绪识别的问题中，音频的语义（linguistic）信息是相对不可靠的。一是在指定情绪下，人的词语选择是不确定的；二是语义信息是和语言的种类相关的，情绪却是与语言种类无关的，用语义信息得到的模型是很难泛化的；三是考虑到最后的应用场景（问答式），词语的种类很有限。因此我觉得最后的多模态信息应该排除语音信息，只考虑非语义信息。

多模态学习的融合算法一般可以分为数据融合（data fusion）、特征融合（feature fusion）和决策融合（decision fusion）三个层面。在大数据时代，多模态的数据往往大容量、大速率，且数据形式多样，有结构化、半结构化等等数据，这些数据位于不同的空间中。直接进行融合不仅存在技术上的困难，而且会带来维度灾难和模型收敛的问题。而对于决策融合，一方面由于人们在表述情感信息的时候是冗余的，决策融合往往会带来分类的错误；另一方面，音频信息和图像信息的独立性假设损失了模态间的互信息。

#### 多模态特征融合方法

特征融合有许多可用的方法，包括经典一些的受限/深度玻尔兹曼机、深度神经网络、TransFormer结构的神经网络、图神经网络、门控神经网络等，一下对一些常用的方法进行介绍和讨论。

**受限/深度玻尔兹曼机（Restricted/Deep Boltzmann Machine）**：玻尔兹曼机是一大类的神经网络模型，但是在实际应用中使用最多的则是RBM。RBM本身模型很简单，只是一个两层的神经网络，因此严格意义上不能算深度学习的范畴。不过深度玻尔兹曼机（Deep Boltzmann Machine，以下简称DBM）可以看做是RBM的推广。因为是概率模型，因此此方法可以很好的解决某个模态的输入有缺失的情况。

**卷积/分类器思想的融合**：将多种模态的特征Resize后以一定方式进行拼接，然后使用1x1卷积或全连接层进行特征融合即可得到复合特征。这种方法易于实现并且具有较高的效率，模态特征之间的耦合度也比较低，但是无法适应部分特征缺失的情况，并且难以在深层次上实现特征空间的匹配。

**基于门控单元的神经网络**：参考LSTM、GNU单元中的遗忘门和重置门的设置，设计出门单元来融合多模态信息。

**具有注意力机制/Transformer的融合模块**：注意力机制可以使模型具有很强的自适应能力，做到动态学习和融合特征。利用自注意力机制融合不同模态之间的信息，然后利用门控模块融合不同层级之间的特征。本质上来讲，Transformer也是一种注意力机制的应用，但是具有更好的泛化能力，自提出并应用在NLP问题上设计出BERT模型后，在许多研究领域大放异彩。

#### 完整的多模态情绪识别方法

吴良庆团队提出一种多任务融合学习网络(Multitask Fusion Learning Network， MFLN)方法来识别多模态情绪。具体而言，将文本信息、图像信息以及声音信息看成是多任务的输人：1)每种模态信息分别通过一个私有的双向ISTM 层进行编码，以学习单个模态内部的变化信息；2)3 种模态信息之间两两结合形成了种组合，通过共享的双向LSTM层，以学习双模态之间的动态交互作用信息；3)联合3种模态的信息，经过同一个共享双向 LSTM 层来学习3 种模态之间的动态联系。最后，把整个网络中学习到的多个模态的内部信息和模态之间的交互信息进行融合，以获取最终的情绪信息。实验结果表明，本文提出的方法可以显著提高多模态情绪识别的性能。

不同于相关工作中提到的方法，本文从多任务学习的角度探究了多模态情绪识别问题。图1为本文提出的多任务融合学习网络的模型框架图，该模型主要包含以下结枸。

1. 特征输人层：将多模态内容中的文本、图像和语音特征输人到神经网络。
2. Intra-modality 层：注重于单个模态 (Uni-modal) 内部的信息，采用的是私有的双向LSTM 层。
3. Inter-modality 层：包含两个部分，分别是双模态(Bimodal) 和三模态(Tri-modal)使用的共享双向 LSTM层。
4. 预测分类层：分别使用单模态信息和多模态融合信息对数据集中的所有情绪类别进行识别，并把对每个情绪类别的识别都作为一个二分类任务，即对多个二分类任务进行预测。

![dadsda](https://s2.loli.net/2023/02/22/kKeQ1VcRSOoiUIG.png)

### AIGC

### 多设备信息共享和调度

## 技术方案

> 初赛阶段完成

### 技术方向

> 指出想要使用技术的所属方向，比如深度学习、IoT等。

本项目将涉及多个领域的技术内容，包括：

- 深度学习与机器学习：用于提取不同设备下信息的特征提取，并在不同的特征空间上对齐
- AIGC：人工智能方法的内容创作
- 推荐系统：使用协同过滤作为主要的推荐系统实现，并实现xxxx（不太了解www）
- 跨平台客户端：设备端侧使用Flutter+原生方案提供高性能、平台深度结合的跨平台方案
- 智能后端：

### 技术选择

### 结果期望

> 给出使用该技术的与其结果，注意给出的预期结果应该是合理、可行的。

## 技术实践

> 复赛阶段完成

### 使用的开发框架及依赖的库

### 技术实践过程

## 结果验证

> 复赛阶段完成

## 参考资料

- [多模态情绪识别调研 - CSDN博客](https://blog.csdn.net/qq_39337332/article/details/113513560)
- [何晖光：多模态情绪识别及跨被试迁移学习 - 机器之心](https://www.jiqizhixin.com/articles/2019-05-07-4)
- [基于多任务学习的多模态情绪识别方法](https://www.jsjkx.com/CN/article/openArticlePDF.jsp?id=18633)